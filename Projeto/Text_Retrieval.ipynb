{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudaholandah/NLP/blob/main/Projeto/Text_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JULgGCViw8IR"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39nOQqcZOEsO",
        "outputId": "e22733f7-829b-4344-ca47-12fcc504a416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RgGXPlLNOJqw"
      },
      "outputs": [],
      "source": [
        "!cp -r '/content/drive/MyDrive/Datasets/cuisine-classification-ingredients' 'cuisine-classification-ingredients'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXBIaW8iNOp3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTT458SZ3Oju"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "!pip install -q -U tf-models-official==2.7.0\n",
        "!pip install -U tfds-nightly\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ggs_g2baLZMZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A_m0pkHhR6gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c615947c-cbc5-496b-d0d4-b9543e368422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "#TFIDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#WORD2VEC\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "#BERT\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp import optimization\n",
        "from sentence_transformers import SentenceTransformer\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NObXC41TNQZj"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5JjYIn_kNSjR"
      },
      "outputs": [],
      "source": [
        "train_path = 'cuisine-classification-ingredients/train.json'\n",
        "test_path = 'cuisine-classification-ingredients/test.json'\n",
        "\n",
        "with open(train_path, 'r') as f:\n",
        "  train_json = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gb4Ib7JJP2ux"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(train_json, columns=['id', 'cuisine', 'ingredients'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YIld3-hEQEc7"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop(['id'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-FJCLP-bOqe"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MRibRNivbUE1"
      },
      "outputs": [],
      "source": [
        "def pre_processing(text):\n",
        "  new = \"\"\n",
        "  for word in text.split(','):\n",
        "    word = re.sub(r'[^\\w\\s]', '', word.lower())\n",
        "    word = re.sub(r'[0-9]+', '', word)\n",
        "    word = re.sub(r'\\boz\\b', '', word)\n",
        "    word = re.sub(r'\\ba taste of\\b', '', word)\n",
        "    new = new + word.strip() + \" \"\n",
        "\n",
        "  return new[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bhmVcEwdQnjh"
      },
      "outputs": [],
      "source": [
        "train_df['ingredients'] = [','.join(x).strip() for x in train_df['ingredients']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4qc9fp0jcaDG"
      },
      "outputs": [],
      "source": [
        "train_df['ingredients'] = [pre_processing(x) for x in train_df['ingredients']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pviX8tN3Ug_K",
        "outputId": "22460899-1a2b-4d84-86d1-87e52181d0fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        romaine lettuce black olives grape tomatoes ga...\n",
              "1        plain flour ground pepper salt tomatoes ground...\n",
              "2        eggs pepper salt mayonaise cooking oil green c...\n",
              "3                           water vegetable oil wheat salt\n",
              "4        black pepper shallots cornflour cayenne pepper...\n",
              "                               ...                        \n",
              "39769    light brown sugar granulated sugar butter warm...\n",
              "39770    kraft zesty italian dressing purple onion broc...\n",
              "39771    eggs citrus fruit raisins sourdough starter fl...\n",
              "39772    boneless chicken skinless thigh minced garlic ...\n",
              "39773    green chile jalapeno chilies onions ground bla...\n",
              "Name: ingredients, Length: 39774, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_df['ingredients']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeJnnAJyR9fn"
      },
      "source": [
        "# Different Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrZ43RFpWubJ"
      },
      "source": [
        "## TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HGfCWcmNR8Pp"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer() #tokenizer=(lambda x : x.split(',')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LlB6_2ujSo-Y"
      },
      "outputs": [],
      "source": [
        "ingredients = train_df['ingredients']\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(ingredients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCzq2JEkkcJb",
        "outputId": "86096125-af40-4bdf-c570-1c8be0931ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abalone' 'abbamele' 'absinthe' ... 'ziti' 'zucchini' 'Ã©pices']\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AFWG6K3bY7TW"
      },
      "outputs": [],
      "source": [
        "tfidf_df = pd.DataFrame(train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "#tfidf_df = tfidf_df.drop([''], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySskzdn86S90",
        "outputId": "d27294e8-727d-49b1-a9d1-2db5049c8ddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3057"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y76wOBybvL5f"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3EA21gQ3vmZU"
      },
      "outputs": [],
      "source": [
        "ingredients = '. '.join(train_df['ingredients'])\n",
        "sentences = nltk.sent_tokenize(ingredients)\n",
        "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G5BJ-0n9vPI0"
      },
      "outputs": [],
      "source": [
        "model_word2vec = Word2Vec(sentences, size=300, min_count=1, window=5, sg=1,workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rbL1SLr85cH"
      },
      "outputs": [],
      "source": [
        "model_word2vec.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "K0LbFMyExr26"
      },
      "outputs": [],
      "source": [
        "def get_embedding_w2v(doc_tokens):\n",
        "    embeddings = []\n",
        "    for tok in doc_tokens:\n",
        "        if tok in model_word2vec.wv.vocab:\n",
        "                embeddings.append(model_word2vec.wv.word_vec(tok))\n",
        "        else:\n",
        "            embeddings.append(np.random.rand(300))\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0tCEvjM2x8fo"
      },
      "outputs": [],
      "source": [
        "senteces_word2vec = train_df['ingredients'].apply(lambda x : get_embedding_w2v(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFMQxIDHk18k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFEr-j0DW3Ui"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0RC03to7dr-",
        "outputId": "373047ba-6c84-4726-d461-1c6ed08a8593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1\n",
            "Preprocessing model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-512_A-8' \n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "print('BERT model selected           :', tfhub_handle_encoder)\n",
        "print('Preprocessing model auto-selected:', tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8UeicBaxOqhA"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.load(tfhub_handle_preprocess)\n",
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lSV1IM2AUlJ1"
      },
      "outputs": [],
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "\n",
        "### https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "### https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/bert_glue.ipynb#scrollTo=aksj743St9ga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXr-RV3OCovw"
      },
      "outputs": [],
      "source": [
        "bert_model_sentence = SentenceTransformer('bert-base-nli-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "U7GRajF_Fv-L"
      },
      "outputs": [],
      "source": [
        "sentence_vecs = bert_model_sentence.encode(train_df['cuisine'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8BLcackYjE2"
      },
      "source": [
        "# Different Classificators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hz6LiwUv_cw"
      },
      "source": [
        "# Text Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n69PkvOowDpm"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vetor1,vetor2):\n",
        "\n",
        "    prod_interno = 0\n",
        "\n",
        "    for i in range(len(vetor1)):\n",
        "        prod_interno += vetor1[i]*vetor2[i]\n",
        "\n",
        "    norma_vetor1 = sum([x**2 for x in vetor1])**0.5\n",
        "    norma_vetor2 = sum([x**2 for x in vetor2])**0.5\n",
        "\n",
        "    return prod_interno/(norma_vetor1*norma_vetor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r2flwRXT9eaJ"
      },
      "outputs": [],
      "source": [
        "categ = train_df['cuisine'][:1000]\n",
        "top10_tfidf = [0] * 10\n",
        "\n",
        "for i in range(len(categ)):\n",
        "    best = []\n",
        "    for j in range(len(categ)):\n",
        "        if i == j: continue\n",
        "        best.append( (cosine_similarity(tfidf_df.iloc[j], tfidf_df.iloc[i]), j))\n",
        "\n",
        "    best.sort(reverse=True)\n",
        "    top = best[:10]\n",
        "\n",
        "    cat_orig = train_df['cuisine'].iloc[i]\n",
        "\n",
        "    for idx, [sim, j] in enumerate(top):\n",
        "        top10_tfidf[idx] += cat_orig in train_df['cuisine'].iloc[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nHIGthWlzchT",
        "outputId": "5eb4e812-f0e0-4405-e7de-5abd4c27c211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[543, 467, 486, 461, 431, 427, 424, 417, 425, 387]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top10_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C1GA-RpZGHdN"
      },
      "outputs": [],
      "source": [
        "categ = train_df['cuisine'][:1000]\n",
        "top10_bert = [0] * 10\n",
        "\n",
        "for i in range(len(categ)):\n",
        "    best = []\n",
        "    for j in range(len(categ)):\n",
        "        if i == j: continue\n",
        "        best.append( (cosine_similarity(sentence_vecs[i], sentence_vecs[j]), j))\n",
        "\n",
        "    best.sort(reverse=True)\n",
        "    top = best[:10]\n",
        "\n",
        "    cat_orig = train_df['cuisine'].iloc[i]\n",
        "\n",
        "    for idx, [sim, j] in enumerate(top):\n",
        "        top10_bert[idx] += cat_orig in train_df['cuisine'].iloc[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hIkEGsp4GR6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e02bcd5-3ebb-4233-abe1-44aa4d4b606f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "top10_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "90PtHB1U0R_r"
      },
      "outputs": [],
      "source": [
        "categ = train_df['cuisine'][:1000]\n",
        "top10_word2vec = [0] * 10\n",
        "\n",
        "for i in range(len(categ)):\n",
        "    best = []\n",
        "    for j in range(len(categ)):\n",
        "        if i == j: continue\n",
        "        best.append( (cosine_similarity(senteces_word2vec[i], senteces_word2vec[j]), j))\n",
        "\n",
        "    best.sort(reverse=True)\n",
        "    top = best[:10]\n",
        "\n",
        "    cat_orig = train_df['cuisine'].iloc[i]\n",
        "\n",
        "    for idx, [sim, j] in enumerate(top):\n",
        "        top10_word2vec[idx] += cat_orig in train_df['cuisine'].iloc[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BWqLeUZZ0d_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517952eb-2f56-4279-f7da-106e3f4ff325"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[595, 556, 551, 538, 508, 506, 486, 484, 474, 480]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "top10_word2vec"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EXBIaW8iNOp3",
        "XrZ43RFpWubJ",
        "y76wOBybvL5f",
        "bFEr-j0DW3Ui",
        "y8BLcackYjE2"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMbk2h/U02wxt64wNgpXg/S",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}