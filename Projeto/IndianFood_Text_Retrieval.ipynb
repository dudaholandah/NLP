{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudaholandah/NLP/blob/main/Projeto/IndianFood_Text_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JULgGCViw8IR"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39nOQqcZOEsO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/MyDrive/NLP-Project/indian-food' 'indian-food'"
      ],
      "metadata": {
        "id": "sFVXDnEj1ISk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXBIaW8iNOp3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NTT458SZ3Oju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b188d693-5155-4a3a-a1fc-4bb7fb940bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting glove-python-binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim --upgrade\n",
        "!pip install glove-python-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A_m0pkHhR6gx"
      },
      "outputs": [],
      "source": [
        "#WORD2VEC\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#GLOVE\n",
        "from glove import Corpus, Glove\n",
        "#Data\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "J_mqxjOc19Hf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NObXC41TNQZj"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'indian-food/indian_food.csv'\n",
        "df_indian = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "yKvncD4rxi2s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_indian.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hoD6uJYQyi3j",
        "outputId": "f4d2779f-6717-4c94-8c13-dd3cceb62142"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             name                                        ingredients  \\\n",
              "0      Balu shahi                    Maida flour, yogurt, oil, sugar   \n",
              "1          Boondi                            Gram flour, ghee, sugar   \n",
              "2  Gajar ka halwa       Carrots, milk, sugar, ghee, cashews, raisins   \n",
              "3          Ghevar  Flour, ghee, kewra, milk, clarified butter, su...   \n",
              "4     Gulab jamun  Milk powder, plain flour, baking powder, ghee,...   \n",
              "\n",
              "         diet  prep_time  cook_time flavor_profile   course        state  \\\n",
              "0  vegetarian         45         25          sweet  dessert  West Bengal   \n",
              "1  vegetarian         80         30          sweet  dessert    Rajasthan   \n",
              "2  vegetarian         15         60          sweet  dessert       Punjab   \n",
              "3  vegetarian         15         30          sweet  dessert    Rajasthan   \n",
              "4  vegetarian         15         40          sweet  dessert  West Bengal   \n",
              "\n",
              "  region  \n",
              "0   East  \n",
              "1   West  \n",
              "2  North  \n",
              "3   West  \n",
              "4   East  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b12eebe-4337-4737-983f-7f1fee29cac3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>flavor_profile</th>\n",
              "      <th>course</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Balu shahi</td>\n",
              "      <td>Maida flour, yogurt, oil, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>45</td>\n",
              "      <td>25</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boondi</td>\n",
              "      <td>Gram flour, ghee, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>80</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gajar ka halwa</td>\n",
              "      <td>Carrots, milk, sugar, ghee, cashews, raisins</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Punjab</td>\n",
              "      <td>North</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ghevar</td>\n",
              "      <td>Flour, ghee, kewra, milk, clarified butter, su...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gulab jamun</td>\n",
              "      <td>Milk powder, plain flour, baking powder, ghee,...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>40</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b12eebe-4337-4737-983f-7f1fee29cac3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b12eebe-4337-4737-983f-7f1fee29cac3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b12eebe-4337-4737-983f-7f1fee29cac3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd1Bwp1Bcut0"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zgjqXtyEcut0"
      },
      "outputs": [],
      "source": [
        "def pre_processing(text):\n",
        "  new = \"\"\n",
        "  for word in text.split(','):\n",
        "    word = re.sub(r'[^\\w\\s]', '', word.lower())\n",
        "    word = re.sub(r'[0-9]+', '', word)\n",
        "    word = re.sub(r'\\boz\\b', '', word)\n",
        "    word = re.sub(r'\\ba taste of\\b', '', word)\n",
        "    new = new + word.strip() + \" \"\n",
        "\n",
        "  return new[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_indian['ingredients'] = [pre_processing(x) for x in df_indian['ingredients']]"
      ],
      "metadata": {
        "id": "DLs5igUXytMt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ingredients = df_indian['ingredients']\n",
        "df_diet = df_indian['diet']\n",
        "df_flavor_profile = df_indian['flavor_profile']\n",
        "df_course = df_indian['course']"
      ],
      "metadata": {
        "id": "kSIBzujzy8rI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeJnnAJyR9fn"
      },
      "source": [
        "# Different Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "3Rl37vqaCItY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_embedding_w2v(tokenizer, model, vocab_size, embedding_dim):\n",
        "  embedding_w2v = np.zeros((vocab_size, embedding_dim))\n",
        "  for word, i in tokenizer.word_index.items():\n",
        "    if word in model.wv:\n",
        "      embedding_w2v[i] = model.wv.get_vector(word)\n",
        "    else:\n",
        "      embedding_w2v[i]=np.random.normal(0,np.sqrt(0.25), embedding_dim)\n",
        "  return embedding_w2v"
      ],
      "metadata": {
        "id": "9seXGB8U9Gd1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7tsa95ynE48i"
      },
      "outputs": [],
      "source": [
        "def sentence_embedding_w2v(model, doc_tokens, embedding_dim):\n",
        "  embeddings = []\n",
        "  for tok in doc_tokens:\n",
        "    if tok in model.wv:\n",
        "      embeddings.append(model.wv.get_vector(tok))\n",
        "    else:\n",
        "      embeddings.append(np.random.normal(0,np.sqrt(0.25), embedding_dim))\n",
        "  return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_ingredients)\n",
        "vocab_size_cuisine = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "XWFgwCcVW00s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EMBEDDING LAYER\n",
        "\n",
        "EMBEDDING_DIM_W2V = 100\n",
        "\n",
        "sentences = [sentence.split() for sentence in df_ingredients]\n",
        "model_word2vec = Word2Vec(sentences, vector_size=EMBEDDING_DIM_W2V, min_count=1, window=5, sg=1,workers=4)\n",
        "\n",
        "embedding_w2v = word_embedding_w2v(tokenizer, model_word2vec, vocab_size_cuisine, EMBEDDING_DIM_W2V)\n",
        "sentences_w2v = df_ingredients.apply(lambda x : sentence_embedding_w2v(model_word2vec, x.split(), EMBEDDING_DIM_W2V))"
      ],
      "metadata": {
        "id": "sOvL-7eLDrwb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe"
      ],
      "metadata": {
        "id": "uOfX_m_m5HQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_glove(glove, vocab_size, embedding_dim):\n",
        "  embedding_glove = np.zeros((vocab_size, embedding_dim))\n",
        "  for i, word in enumerate(glove.dictionary):\n",
        "    embedding_glove[i+1] = glove.word_vectors[i]\n",
        "  return embedding_glove"
      ],
      "metadata": {
        "id": "ZNQQnNMUGrKU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tw7jzPAgGF8B"
      },
      "outputs": [],
      "source": [
        "def sentence_embedding_glove(model, doc_tokens, embedding_dim):\n",
        "  embeddings = []\n",
        "  for tok in doc_tokens:\n",
        "    if tok in glove.dictionary:\n",
        "      embeddings.append(glove.word_vectors[glove.dictionary[tok]])\n",
        "    else:\n",
        "      embeddings.append(np.random.normal(0,np.sqrt(0.25), embedding_dim))\n",
        "  return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = Corpus() \n",
        " \n",
        "sentences = [sentence.split() for sentence in df_ingredients]\n",
        "corpus.fit(sentences, window=10)"
      ],
      "metadata": {
        "id": "rjV8P7qfEj-g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EMBEDDING LAYER\n",
        "\n",
        "EMBEDDING_DIM_GLV = 100\n",
        "\n",
        "glove = Glove(no_components=EMBEDDING_DIM_GLV, learning_rate=0.05)\n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=2)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "embedding_glove = create_embedding_glove(glove, vocab_size_cuisine, EMBEDDING_DIM_GLV)\n",
        "sentences_glove = df_ingredients.apply(lambda x : sentence_embedding_glove(glove, x.split(), EMBEDDING_DIM_GLV))"
      ],
      "metadata": {
        "id": "xr9rXW2hE4oZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hz6LiwUv_cw"
      },
      "source": [
        "# Text Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "VtDGtjtD0mwX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_retrieval(dataset, embedding):\n",
        "  top10 = [0] * 10\n",
        "  size = len(dataset)\n",
        "\n",
        "  for i in range(size):\n",
        "    similarity = cosine_similarity([embedding[i]], embedding[:size])\n",
        "    similarity = [(similarity, idx) for idx,similarity in enumerate(similarity[0])]\n",
        "\n",
        "    similarity.sort(reverse=True)\n",
        "    top = similarity[1:11]\n",
        "\n",
        "    cat_orig = dataset.iloc[i]\n",
        "\n",
        "    for idx, [sim, j] in enumerate(top):\n",
        "      top10[idx] += cat_orig in dataset.iloc[j]\n",
        "\n",
        "  return top10"
      ],
      "metadata": {
        "id": "CQ_NfLer_8s5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec"
      ],
      "metadata": {
        "id": "YwpPjHEVyUzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "C1GA-RpZGHdN"
      },
      "outputs": [],
      "source": [
        "top10_diet_word2vec = text_retrieval(df_diet, sentences_w2v.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hIkEGsp4GR6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fef8a5-b85c-4272-d765-5e4dead933e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[233, 235, 233, 230, 230, 232, 228, 228, 234, 228]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "top10_diet_word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tw3zLlg7ds8A"
      },
      "outputs": [],
      "source": [
        "top10_flavor_profile_word2vec = text_retrieval(df_flavor_profile, sentences_w2v.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672a5ecf-ffe3-446d-e23d-1be309988eda",
        "id": "YB6M-pbxds8B"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[168, 164, 164, 166, 155, 156, 154, 154, 157, 130]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "top10_flavor_profile_word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UYU7tGbqeDuJ"
      },
      "outputs": [],
      "source": [
        "top10_course_word2vec = text_retrieval(df_course, sentences_w2v.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9791aeb-61fb-44db-cd30-0c36e7a6dcf7",
        "id": "Rt6OlWRUeDuJ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[164, 164, 169, 169, 166, 157, 151, 150, 152, 144]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "top10_course_word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe"
      ],
      "metadata": {
        "id": "cimLLwWuyXQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "n8f3_4d7eNUT"
      },
      "outputs": [],
      "source": [
        "top10_diet_glove = text_retrieval(df_diet, sentences_glove.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3828a398-93e5-417a-a9d0-bec216587d78",
        "id": "ykWbqJ2ceNUU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[236, 240, 233, 235, 236, 231, 234, 231, 230, 227]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "top10_diet_glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "98jphzT-eNUU"
      },
      "outputs": [],
      "source": [
        "top10_flavor_profile_glove = text_retrieval(df_flavor_profile, sentences_glove.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145c9f2e-9be4-4be1-8a23-69ac43035ec3",
        "id": "zM1cEyASeNUU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[168, 177, 167, 166, 176, 171, 170, 162, 153, 148]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "top10_flavor_profile_glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4xaY3dO3eNUU"
      },
      "outputs": [],
      "source": [
        "top10_course_glove = text_retrieval(df_course, sentences_glove.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d52cafd-eb08-45f2-fd39-36450da5dc65",
        "id": "lawj1gzBeNUU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[166, 174, 168, 161, 172, 170, 175, 160, 152, 144]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "top10_course_glove"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EXBIaW8iNOp3",
        "XrZ43RFpWubJ",
        "y76wOBybvL5f",
        "bFEr-j0DW3Ui",
        "y8BLcackYjE2"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPSUqUNonv5KPP12Kbhlu5t",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}